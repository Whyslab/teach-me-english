#!/usr/bin/env python3
import argparse
import sqlite3
import time
import random
from dataclasses import dataclass
from typing import Optional
from yt_dlp import YoutubeDL

@dataclass
class MatchResult:
    word: str
    video_id: str
    start_time: float

class YouTubeFinder:
    def __init__(self):
        self.ydl_opts = {
            "quiet": True,
            "no_warnings": True,
            "skip_download": True,
            "writesubtitles": True,
            "writeautomaticsub": True,
            "subtitleslangs": ["en.*"],
            "extract_flat": False, # –ù–∞–º –Ω—É–∂–Ω—ã –ø–æ–ª–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ, –Ω–µ flat
            "user_agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36"
        }

    def find(self, word: str) -> Optional[MatchResult]:
        # –ò—â–µ–º –≤–∏–¥–µ–æ, –≥–¥–µ —Å–ª–æ–≤–æ —Ç–æ—á–Ω–æ –ø—Ä–æ–∏–∑–Ω–æ—Å–∏—Ç—Å—è
        query = f"sentence with the word {word} english"
        try:
            with YoutubeDL(self.ydl_opts) as ydl:
                # –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ 1 —Å–∞–º–æ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–µ –≤–∏–¥–µ–æ, —á—Ç–æ–±—ã –Ω–µ —Å–ø–∞–º–∏—Ç—å
                search_data = ydl.extract_info(f"ytsearch1:{query}", download=False)
                
                if not search_data or 'entries' not in search_data or not search_data['entries']:
                    return None
                
                entry = search_data['entries'][0]
                v_id = entry['id']
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Å—É–±—Ç–∏—Ç—Ä–æ–≤ –≤ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö, –∫–æ—Ç–æ—Ä—ã–µ –ø—Ä–∏—Å–ª–∞–ª YouTube
                subtitles = entry.get('requested_subtitles') or entry.get('subtitles') or entry.get('automatic_captions')
                
                if subtitles:
                    # –ï—Å–ª–∏ –Ω–∞—à–ª–∏ –≤–∏–¥–µ–æ, –ø—Ä–æ—Å—Ç–æ –±–µ—Ä–µ–º –µ–≥–æ ID. 
                    # –ù–∞–π—Ç–∏ —Ç–æ—á–Ω—É—é —Å–µ–∫—É–Ω–¥—É –±–µ–∑ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è —Ñ–∞–π–ª–∞ —Å–ª–æ–∂–Ω–æ, 
                    # –ø–æ—ç—Ç–æ–º—É —Å—Ç–∞–≤–∏–º 0.0 –∏–ª–∏ 5.0 (–Ω–∞—á–∞–ª–æ), –≥–ª–∞–≤–Ω–æ–µ ‚Äî ID –≤–∏–¥–µ–æ –≤ –±–∞–∑–µ!
                    return MatchResult(word, v_id, 5.0)
        except Exception as e:
            # print(f"–û—à–∏–±–∫–∞: {e}")
            return None
        return None

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--db", default="./vocab.db")
    parser.add_argument("--limit", type=int, default=5)
    args = parser.parse_args()

    conn = sqlite3.connect(args.db)
    cur = conn.cursor()
    
    # –ë–µ—Ä–µ–º —Å–ª–æ–≤–∞ –¥–ª–∏–Ω–Ω–µ–µ 3 –±—É–∫–≤ (–ø—Ä–æ–ø—É—Å–∫–∞–µ–º –∞—Ä—Ç–∏–∫–ª–∏)
    cur.execute("""
        SELECT DISTINCT original FROM words 
        WHERE (videoId IS NULL OR videoId = '') 
          AND length(original) > 3 
        LIMIT ?
    """, (args.limit,))
    
    words = [r[0] for r in cur.fetchall()]
    
    if not words:
        print("‚úÖ –í—Å–µ —Å–ª–æ–≤–∞ —É–∂–µ –Ω–∞–π–¥–µ–Ω—ã!")
        return

    finder = YouTubeFinder()
    print(f"üöÄ –ó–∞–ø—É—Å–∫ –æ–±—Ö–æ–¥–Ω–æ–≥–æ –º–µ—Ç–æ–¥–∞ –¥–ª—è {len(words)} —Å–ª–æ–≤...")

    for i, word in enumerate(words, start=1):
        res = finder.find(word)
        if res:
            cur.execute("UPDATE words SET videoId=?, startTime=? WHERE original=?", (res.video_id, res.start_time, word))
            conn.commit()
            print(f"[{i}/{len(words)}] ‚úÖ {word} -> {res.video_id}")
        else:
            print(f"[{i}/{len(words)}] ‚ùå {word} -> –Ω–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–±–∏—Ç—å –±–ª–æ–∫")
        
        # –ñ–¥–µ–º –ø–æ–¥–æ–ª—å—à–µ, —á—Ç–æ–±—ã YouTube –æ—Å—Ç—ã–ª
        time.sleep(random.uniform(5, 10))

    conn.close()
    print("üèÅ –ì–æ—Ç–æ–≤–æ.")

if __name__ == "__main__":
    main()


===============================
–†–ê–ë–û–ß–ò–ô –°–û–§–¢ –ö–û–¢–û–†–´–ô –î–ï–õ–ê–ï–¢ VIDEOiD
===============================


–≤–æ –ø–µ—Ä–≤—ã—Ö –Ω–µ—Ç –ø–æ–ª—è –≤–≤–æ–¥–∞ –∫—É–¥–∞ –≤–≤–æ–¥–∏—Ç—å –ø–µ—Ä–µ–≤–æ–¥ –≤–æ –≤—Ç–æ—Ä—ã—Ö –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ –≤—ã–π—Ç–∏ –∏–∑ —ç—Ç–æ–≥–æ —Ä–µ–∂–∏–º–∞ –≤ —Ç—Ä–µ—Ç–∏—Ö —è —Ö–æ—á—É —á—Ç–æ–±—ã –ø–æ–∫–∞–∑—ã–≤–∞–ª–∏ –≤–∏–¥–µ–æ —Å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–≥–æ —Ç–∞–π–º–∫–æ–¥–∞ –∏ –≤–∏–¥–µ–æ –∑–∞–∫–∞–Ω—á–∏–≤–∞–ª–æ—Å—å –Ω–∞ —Ç–∞–π–º–∫–æ–¥–µ –¥–∞–ª—å—à–µ –Ω–µ –ø–æ–Ω—è—Ç–Ω–æ –∫–∞–∫–∏–µ —Å–ª–æ–≤–æ —Ç—ã —Å–µ–π—á–∞—Å –ø—Ä–æ—Ö–æ–¥–∏—à—å –Ω—É–∂–Ω–æ —ç—Ç–æ —Ç–æ–∂–µ –¥–æ–±–∞–≤–∏—Ç—å —Å–æ–æ—Ç–≤–µ—Å—Ç–≤–µ–Ω–Ω–æ –¥–±–∞–≤–∏—Ç—å –Ω–µ —Ç–æ–ª—å–∫–æ –ø–æ–ª–µ–µ –≤–≤–æ–¥–∞ –Ω–æ –∏ –∫–Ω–æ–ø–∫—É —Ç–∏–ø–æ –¥–∞–ª–µ–µ –∏ –æ–ø–æ–≤–µ—â–µ–Ω–∏–µ –ø—Ä–∞–≤–∏–ª—å–Ω–æ\–Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ —Å–æ—Ñ—Ç –ø—Ä–æ—Å—Ç–æ –±–µ—Ä–µ—Ç –≤–∏–¥–µ–æ –ø–æ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º—É –≥–¥–µ –±—ã–ª–æ –Ω—É–∂–Ω–æ–µ —Å–ª–æ–≤–æ –∫–∞–∫ —è –ø–æ–Ω—è–ª –∏ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –≤–∏–¥–µ–æ —Å 5 —Å–µ–∫—É–Ω–¥—ã –∞ –Ω–µ —Å –º–æ–º–µ–Ω—Ç–∞ –≥–¥–µ –Ω–∞—á–∞–ª–æ—Å—å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ —Å —ç—Ç–∏–º —Å–ª–æ–≤–æ–º 


#!/usr/bin/env python3
"""
refine_segments.py v5
---------------------
–ü—Ä–∏ 429 –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –º–µ–Ω—è–µ—Ç IP —á–µ—Ä–µ–∑ Tor –∏–ª–∏ —Å–ø–∏—Å–æ–∫ –ø—Ä–æ–∫—Å–∏.

–í–∞—Ä–∏–∞–Ω—Ç—ã –∑–∞–ø—É—Å–∫–∞:
  # –ß–µ—Ä–µ–∑ Tor (–∞–≤—Ç–æ—Å–º–µ–Ω–∞ IP –ø—Ä–∏ 429):
  python refine_segments.py --db ./vocab.db --tor

  # –ß–µ—Ä–µ–∑ —Å–ø–∏—Å–æ–∫ –ø—Ä–æ–∫—Å–∏ (—Ñ–∞–π–ª —Å –ø—Ä–æ–∫—Å–∏ –ø–æ –æ–¥–Ω–æ–º—É –Ω–∞ —Å—Ç—Ä–æ–∫—É):
  python refine_segments.py --db ./vocab.db --proxy-list ./proxies.txt

  # –ü—Ä–æ—Å—Ç–æ —Å cookies (–±–µ–∑ —Å–º–µ–Ω—ã IP):
  python refine_segments.py --db ./vocab.db --cookies-file ./cookies.txt

–£—Å—Ç–∞–Ω–æ–≤–∫–∞ Tor:
  pip install requests[socks] stem
  –°–∫–∞—á–∞–π Tor: https://www.torproject.org/download/tor/
  –ó–∞–ø—É—Å—Ç–∏ tor.exe (–∏–ª–∏ tor –≤ Linux/Mac)
"""

from __future__ import annotations

import argparse
import json
import re
import random
import sqlite3
import time
from dataclasses import dataclass
from datetime import datetime, timezone
from typing import Optional

try:
    from yt_dlp import YoutubeDL
except ImportError:
    print("‚ùå pip install yt-dlp")
    raise SystemExit(1)


# ‚îÄ‚îÄ‚îÄ Tor / –ø—Ä–æ–∫—Å–∏ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

class ProxyRotator:
    """–†–æ—Ç–∞—Ç–æ—Ä –ø—Ä–æ–∫—Å–∏ ‚Äî Tor –∏–ª–∏ —Å–ø–∏—Å–æ–∫ –ø—Ä–æ–∫—Å–∏ –∏–∑ —Ñ–∞–π–ª–∞."""

    def __init__(self, mode: str, proxies: list[str] | None = None,
                 tor_host: str = "127.0.0.1", tor_port: int = 9050,
                 tor_control_port: int = 9051, tor_password: str = ""):
        self.mode       = mode        # "tor" | "list" | "none"
        self.proxies    = proxies or []
        self.proxy_idx  = 0
        self.tor_host   = tor_host
        self.tor_port   = tor_port
        self.tor_control = tor_control_port
        self.tor_password = tor_password
        self._tor_controller = None

        if mode == "tor":
            self._init_tor()

    def _init_tor(self):
        try:
            from stem import Signal
            from stem.control import Controller
            ctrl = Controller.from_port(port=self.tor_control)

            # –ü—Ä–æ–±—É–µ–º –≤—Å–µ –º–µ—Ç–æ–¥—ã –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏ –ø–æ –æ—á–µ—Ä–µ–¥–∏
            authenticated = False
            errors = []

            # 1. Cookie-—Ñ–∞–π–ª (–±–∏–Ω–∞—Ä–Ω—ã–π ‚Äî stem —á–∏—Ç–∞–µ—Ç —Å–∞–º)
            if not authenticated:
                try:
                    ctrl.authenticate()
                    authenticated = True
                except Exception as e:
                    errors.append(f"cookie: {e}")

            # 2. –ü—É—Å—Ç–æ–π –ø–∞—Ä–æ–ª—å
            if not authenticated:
                try:
                    ctrl.authenticate(password="")
                    authenticated = True
                except Exception as e:
                    errors.append(f"empty pass: {e}")

            # 3. –ó–∞–¥–∞–Ω–Ω—ã–π –ø–∞—Ä–æ–ª—å
            if not authenticated and self.tor_password:
                try:
                    ctrl.authenticate(password=self.tor_password)
                    authenticated = True
                except Exception as e:
                    errors.append(f"password: {e}")

            if not authenticated:
                raise Exception(" | ".join(errors))

            self._tor_controller = ctrl
            print(f"  üßÖ Tor –ø–æ–¥–∫–ª—é—á—ë–Ω (–∫–æ–Ω—Ç—Ä–æ–ª—å: –ø–æ—Ä—Ç {self.tor_control})")

        except Exception as e:
            print(f"  ‚ö†Ô∏è  Tor –∫–æ–Ω—Ç—Ä–æ–ª–ª–µ—Ä –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}")
            print("     –°–º–µ–Ω–∞ IP –Ω–µ –±—É–¥–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å, –Ω–æ –ø—Ä–æ–∫—Å–∏ –≤—Å—ë —Ä–∞–≤–Ω–æ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è.")
            self._tor_controller = None

    @property
    def current_proxy(self) -> str | None:
        if self.mode == "tor":
            return f"socks5://{self.tor_host}:{self.tor_port}"
        if self.mode == "list" and self.proxies:
            return self.proxies[self.proxy_idx % len(self.proxies)]
        return None

    def rotate(self) -> str | None:
        """–ú–µ–Ω—è–µ—Ç IP. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –Ω–æ–≤—ã–π –ø—Ä–æ–∫—Å–∏."""
        if self.mode == "tor":
            return self._rotate_tor()
        if self.mode == "list":
            return self._rotate_list()
        return None

    def _rotate_tor(self) -> str:
        if self._tor_controller:
            try:
                from stem import Signal
                self._tor_controller.signal(Signal.NEWNYM)
                time.sleep(3)  # Tor –Ω—É–∂–Ω–æ –≤—Ä–µ–º—è –Ω–∞ —Å–º–µ–Ω—É —Ü–µ–ø–æ—á–∫–∏
                print("  üîÑ Tor: –Ω–æ–≤—ã–π IP –ø–æ–ª—É—á–µ–Ω")
            except Exception as e:
                print(f"  ‚ö†Ô∏è  –û—à–∏–±–∫–∞ —Å–º–µ–Ω—ã Tor IP: {e}")
        else:
            # –ë–µ–∑ –∫–æ–Ω—Ç—Ä–æ–ª–ª–µ—Ä–∞ –ø—Ä–æ—Å—Ç–æ –∂–¥—ë–º ‚Äî Tor —Å–∞–º –º–µ–Ω—è–µ—Ç —Ü–µ–ø–æ—á–∫—É —Ä–∞–∑ –≤ 10 –º–∏–Ω
            print("  ‚è≥ Tor –±–µ–∑ –∫–æ–Ω—Ç—Ä–æ–ª–ª–µ—Ä–∞ ‚Äî –∂–¥—ë–º 15—Å...")
            time.sleep(15)
        return f"socks5://{self.tor_host}:{self.tor_port}"

    def _rotate_list(self) -> str | None:
        if not self.proxies:
            return None
        self.proxy_idx = (self.proxy_idx + 1) % len(self.proxies)
        proxy = self.proxies[self.proxy_idx]
        print(f"  üîÑ –ù–æ–≤—ã–π –ø—Ä–æ–∫—Å–∏: {proxy}")
        return proxy


def load_proxy_list(path: str) -> list[str]:
    proxies = []
    with open(path) as f:
        for line in f:
            line = line.strip()
            if line and not line.startswith("#"):
                # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ö–µ–º—É –µ—Å–ª–∏ –Ω–µ—Ç
                if not line.startswith(("http", "socks")):
                    line = "socks5://" + line
                proxies.append(line)
    print(f"  üìã –ó–∞–≥—Ä—É–∂–µ–Ω–æ –ø—Ä–æ–∫—Å–∏: {len(proxies)}")
    return proxies


# ‚îÄ‚îÄ‚îÄ –°—Ç—Ä—É–∫—Ç—É—Ä—ã ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

@dataclass
class Chunk:
    text:  str
    start: float
    end:   float

EMPTY_VALUES = ("", "Check video for context", None)

DEFAULT_COLUMNS = {
    "startTime":         "REAL",
    "endTime":           "REAL",
    "subtitleText":      "TEXT",
    "subtitleLang":      "TEXT",
    "subtitleUpdatedAt": "TEXT",
}


# ‚îÄ‚îÄ‚îÄ YDL ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

def _build_ydl_opts(proxy: str | None, cookies_file: str | None) -> dict:
    opts = {
        "quiet":             True,
        "no_warnings":       True,
        "skip_download":     True,
        "extract_flat":      False,
        "writesubtitles":    True,
        "writeautomaticsub": True,
        "subtitleslangs":    ["en"],
        "subtitlesformat":   "json3",
        "retries":           3,
        "sleep_interval":    1,
        "max_sleep_interval": 5,
        "user_agent": (
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
            "AppleWebKit/537.36 (KHTML, like Gecko) "
            "Chrome/124.0.0.0 Safari/537.36"
        ),
    }
    if proxy:
        opts["proxy"] = proxy
    if cookies_file:
        opts["cookiefile"] = cookies_file
    return opts


def fetch_chunks(video_id: str, proxy: str | None,
                 cookies_file: str | None) -> tuple[list[Chunk], str]:
    url      = f"https://www.youtube.com/watch?v={video_id}"
    ydl_opts = _build_ydl_opts(proxy, cookies_file)

    with YoutubeDL(ydl_opts) as ydl:
        info = ydl.extract_info(url, download=False)

    if not info:
        raise RuntimeError("yt-dlp –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç")

    subs_url = lang = None
    for key in ("subtitles", "automatic_captions"):
        lang_data = (info.get(key) or {}).get("en", [])
        for fmt in lang_data:
            if fmt.get("ext") in ("json3", "srv3"):
                subs_url = fmt.get("url")
                lang = "en"
                break
        if subs_url:
            break

    if not subs_url:
        raise RuntimeError("–°—É–±—Ç–∏—Ç—Ä—ã –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")

    # –°–∫–∞—á–∏–≤–∞–µ–º —á–µ—Ä–µ–∑ yt-dlp (—Å —Ç–µ–º–∏ –∂–µ cookies/proxy)
    with YoutubeDL({**ydl_opts, "quiet": True}) as ydl:
        raw = ydl.urlopen(subs_url).read().decode("utf-8")

    data   = json.loads(raw)
    chunks = _parse_json3(data)
    if not chunks:
        raise RuntimeError("–°—É–±—Ç–∏—Ç—Ä—ã –ø—É—Å—Ç—ã–µ –ø–æ—Å–ª–µ –ø–∞—Ä—Å–∏–Ω–≥–∞")

    return chunks, lang or "en"


def _parse_json3(data: dict) -> list[Chunk]:
    result: list[Chunk] = []
    for event in data.get("events", []):
        start_ms = event.get("tStartMs", 0)
        dur_ms   = event.get("dDurationMs", 0)
        text = "".join(s.get("utf8", "") for s in event.get("segs", [])).strip()
        text = _clean(text)
        if text:
            result.append(Chunk(text=text,
                                start=start_ms / 1000.0,
                                end=(start_ms + dur_ms) / 1000.0))
    return result


def _clean(text: str) -> str:
    text = text.replace("\n", " ")
    text = re.sub(r"\[(?:music|applause|laughter|noise|\s)+\]", "", text, flags=re.IGNORECASE)
    return re.sub(r"\s+", " ", text).strip()


# ‚îÄ‚îÄ‚îÄ –ü–æ–∏—Å–∫ —Å–ª–æ–≤–∞ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

def find_sentence(chunks: list[Chunk], word: str,
                  max_expand: int = 6) -> Optional[tuple[float, float, str]]:
    pattern = re.compile(r"(?<!\w)" + re.escape(word) + r"(?!\w)", re.IGNORECASE)
    hit = next((i for i, c in enumerate(chunks) if pattern.search(c.text)), None)
    if hit is None:
        return None

    left = hit
    while left > 0 and (hit - left) < max_expand:
        if re.search(r"[.!?‚Ä¶]\s*$", chunks[left - 1].text):
            break
        left -= 1

    right = hit
    while right < len(chunks) - 1 and (right - hit) < max_expand:
        if re.search(r"[.!?‚Ä¶]\s*$", chunks[right].text):
            break
        right += 1
        if re.search(r"[.!?‚Ä¶]\s*$", chunks[right].text):
            break

    sentence = re.sub(r"\s+", " ",
                      " ".join(c.text for c in chunks[left:right + 1])).strip()
    start = round(max(0.0, chunks[left].start - 0.5), 2)
    end   = round(chunks[right].end + 0.5, 2)
    return start, end, sentence


# ‚îÄ‚îÄ‚îÄ –ë–î ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

def ensure_columns(cur: sqlite3.Cursor) -> None:
    cur.execute("PRAGMA table_info(words)")
    existing = {row[1] for row in cur.fetchall()}
    for col, typ in DEFAULT_COLUMNS.items():
        if col not in existing:
            cur.execute(f"ALTER TABLE words ADD COLUMN {col} {typ}")
            print(f"  ‚úö –î–æ–±–∞–≤–ª–µ–Ω–∞ –∫–æ–ª–æ–Ω–∫–∞: {col}")


def select_words(cur: sqlite3.Cursor, limit: int) -> list[tuple]:
    placeholders = ",".join("?" * len(EMPTY_VALUES))
    cur.execute(f"""
        SELECT rowid, original, videoId FROM words
        WHERE  COALESCE(videoId, '') != ''
          AND  length(COALESCE(original,'')) >= 2
          AND  (subtitleText IS NULL OR TRIM(subtitleText) IN ({placeholders}))
        LIMIT  ?
    """, (*EMPTY_VALUES, limit))
    return cur.fetchall()


# ‚îÄ‚îÄ‚îÄ –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

def refine(args: argparse.Namespace) -> None:

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–æ—Ç–∞—Ç–æ—Ä –ø—Ä–æ–∫—Å–∏
    if args.tor:
        rotator = ProxyRotator(
            mode="tor",
            tor_host=args.tor_host,
            tor_port=args.tor_port,
            tor_control_port=args.tor_control_port,
            tor_password=args.tor_password,
        )
    elif args.proxy_list:
        proxies = load_proxy_list(args.proxy_list)
        if not proxies:
            print("‚ùå –§–∞–π–ª –ø—Ä–æ–∫—Å–∏ –ø—É—Å—Ç–æ–π!")
            return
        rotator = ProxyRotator(mode="list", proxies=proxies)
    elif args.proxy:
        rotator = ProxyRotator(mode="list", proxies=[args.proxy])
    else:
        rotator = ProxyRotator(mode="none")

    conn = sqlite3.connect(args.db)
    cur  = conn.cursor()
    ensure_columns(cur)
    conn.commit()

    rows = select_words(cur, args.limit)
    if not rows:
        print("‚ú® –ù–µ—Ç —Å–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏.")
        conn.close()
        return

    print(f"üìã –°–ª–æ–≤ –∫ –æ–±—Ä–∞–±–æ—Ç–∫–µ: {len(rows)}")
    if rotator.current_proxy:
        print(f"  üåê –ü—Ä–æ–∫—Å–∏: {rotator.current_proxy}")
    if args.cookies_file:
        print(f"  üç™ Cookies: {args.cookies_file}")
    print()

    ok = fail_count = 0

    for idx, (rowid, word, video_id) in enumerate(rows, 1):
        if not word or not video_id:
            continue

        print(f"[{idx}/{len(rows)}] üîç '{word}' ({video_id})", end=" ... ", flush=True)

        # –ü—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å—É–±—Ç–∏—Ç—Ä—ã ‚Äî –ø—Ä–∏ 429 –º–µ–Ω—è–µ–º IP –∏ –ø–æ–≤—Ç–æ—Ä—è–µ–º
        max_retries = max(1, len(rotator.proxies) if rotator.mode == "list" else 3)
        chunks = lang = None

        for attempt in range(1, max_retries + 2):
            try:
                chunks, lang = fetch_chunks(video_id, rotator.current_proxy, args.cookies_file)
                fail_count = 0
                break

            except KeyboardInterrupt:
                print("\n‚õî –ü—Ä–µ—Ä–≤–∞–Ω–æ.")
                conn.close()
                return

            except Exception as exc:
                msg = str(exc)
                is_rate  = any(x in msg for x in ("429", "Too Many", "blocked", "Forbidden", "403"))
                no_subs  = "–Ω–µ –Ω–∞–π–¥–µ–Ω—ã" in msg or "no subtitle" in msg.lower() or "not found" in msg.lower()

                if no_subs:
                    print("‚ö†Ô∏è  –Ω–µ—Ç —Å—É–±—Ç–∏—Ç—Ä–æ–≤")
                    cur.execute("UPDATE words SET subtitleText=? WHERE rowid=?",
                                ("Check video for context", rowid))
                    conn.commit()
                    chunks = None
                    break

                if is_rate:
                    print(f"‚ùå 429", end="")
                    if attempt <= max_retries:
                        print(f" ‚Äî –º–µ–Ω—è—é IP (–ø–æ–ø—ã—Ç–∫–∞ {attempt})...", end=" ", flush=True)
                        rotator.rotate()
                        continue  # –ø–æ–≤—Ç–æ—Ä—è–µ–º —Å –Ω–æ–≤—ã–º IP
                    else:
                        print(f" ‚Äî –ø–æ–ø—ã—Ç–∫–∏ –∏—Å—á–µ—Ä–ø–∞–Ω—ã")
                        fail_count += 1

                else:
                    print(f"‚ùå {msg[:80]}")
                    fail_count += 1

                break

        if fail_count >= args.max_consecutive_errors:
            print(f"üõë {fail_count} –æ—à–∏–±–æ–∫ –ø–æ–¥—Ä—è–¥ ‚Äî –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—é—Å—å.")
            break

        if chunks is None:
            if idx < len(rows):
                time.sleep(random.uniform(1, 3))
            continue

        # –ò—â–µ–º —Å–ª–æ–≤–æ –≤ —Å—É–±—Ç–∏—Ç—Ä–∞—Ö
        result = find_sentence(chunks, word)
        if result is None:
            print("‚ö†Ô∏è  —Å–ª–æ–≤–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –≤ —Å—É–±—Ç–∏—Ç—Ä–∞—Ö")
            cur.execute("UPDATE words SET subtitleText=? WHERE rowid=?",
                        ("Check video for context", rowid))
            conn.commit()
        else:
            start, end, sentence = result
            now_iso = datetime.now(timezone.utc).isoformat(timespec="seconds")
            cur.execute("""
                UPDATE words
                SET startTime=?, endTime=?, subtitleText=?, subtitleLang=?, subtitleUpdatedAt=?
                WHERE rowid=?
            """, (start, end, sentence, lang, now_iso, rowid))
            conn.commit()
            preview = sentence[:70] + ("‚Ä¶" if len(sentence) > 70 else "")
            print(f"‚úÖ [{start}s‚Äì{end}s]  ¬´{preview}¬ª")
            ok += 1

        if idx < len(rows):
            time.sleep(random.uniform(args.sleep_min, args.sleep_max))

    conn.close()
    print(f"\nüèÅ –ì–æ—Ç–æ–≤–æ!  ‚úÖ {ok}  ‚ùå {len(rows) - ok}")


# ‚îÄ‚îÄ‚îÄ CLI ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

def main() -> None:
    p = argparse.ArgumentParser(
        description="Refine subtitle segments ‚Äî —Å –∞–≤—Ç–æ-—Å–º–µ–Ω–æ–π IP –ø—Ä–∏ 429",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
–í–∞—Ä–∏–∞–Ω—Ç—ã –∑–∞–ø—É—Å–∫–∞:

  1. Tor (–∞–≤—Ç–æ—Å–º–µ–Ω–∞ IP –ø—Ä–∏ –∫–∞–∂–¥–æ–º 429):
     –°–Ω–∞—á–∞–ª–∞ —É—Å—Ç–∞–Ω–æ–≤–∏ –∏ –∑–∞–ø—É—Å—Ç–∏ Tor:
       pip install stem
       –°–∫–∞—á–∞–π tor.exe: https://www.torproject.org/download/tor/
       –ó–∞–ø—É—Å—Ç–∏ tor.exe
     –ü–æ—Ç–æ–º:
       python refine_segments.py --db ./vocab.db --tor

  2. –°–ø–∏—Å–æ–∫ –ø—Ä–æ–∫—Å–∏ (—Ñ–∞–π–ª proxies.txt, –ø–æ –æ–¥–Ω–æ–º—É –Ω–∞ —Å—Ç—Ä–æ–∫—É):
     python refine_segments.py --db ./vocab.db --proxy-list ./proxies.txt
     –§–æ—Ä–º–∞—Ç —Å—Ç—Ä–æ–∫: 192.168.1.1:1080  –∏–ª–∏  socks5://user:pass@host:port

  3. –û–¥–∏–Ω –ø—Ä–æ–∫—Å–∏:
     python refine_segments.py --db ./vocab.db --proxy "socks5://127.0.0.1:1080"

  4. –¢–æ–ª—å–∫–æ cookies (–±–µ–∑ —Å–º–µ–Ω—ã IP):
     python refine_segments.py --db ./vocab.db --cookies-file ./cookies.txt
        """
    )
    p.add_argument("--db",            default="./vocab.db")
    p.add_argument("--limit",         type=int,   default=100)
    p.add_argument("--cookies-file",  default=None)

    # –ü—Ä–æ–∫—Å–∏
    g = p.add_mutually_exclusive_group()
    g.add_argument("--tor",        action="store_true", help="–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Tor —Å –∞–≤—Ç–æ—Å–º–µ–Ω–æ–π IP")
    g.add_argument("--proxy-list", default=None,        help="–§–∞–π–ª —Å–æ —Å–ø–∏—Å–∫–æ–º –ø—Ä–æ–∫—Å–∏")
    g.add_argument("--proxy",      default=None,        help="–û–¥–∏–Ω –ø—Ä–æ–∫—Å–∏ URL")

    # Tor –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
    p.add_argument("--tor-host",         default="127.0.0.1")
    p.add_argument("--tor-port",         type=int, default=9050)
    p.add_argument("--tor-control-port", type=int, default=9051)
    p.add_argument("--tor-password",     default="",
                   help="–ü–∞—Ä–æ–ª—å Tor –∫–æ–Ω—Ç—Ä–æ–ª–ª–µ—Ä–∞ (–µ—Å–ª–∏ –∑–∞–¥–∞–Ω –≤ torrc)")

    # –ü–∞—É–∑—ã –∏ –ª–∏–º–∏—Ç—ã
    p.add_argument("--sleep-min",             type=float, default=3.0)
    p.add_argument("--sleep-max",             type=float, default=8.0)
    p.add_argument("--max-consecutive-errors", type=int,  default=10)

    args = p.parse_args()
    args.sleep_max = max(args.sleep_min, args.sleep_max)
    refine(args)


if __name__ == "__main__":
    main()


    ============================
        –°–û–§–¢ –ö–û–¢–û–†–´–ô –ò–©–ï–¢ –¢–ê–ô–ú–ö–û–î–´ (TOR)
        ========================================